## Applied Machine Learning — Day-wise Schedule (dates removed)

Below is the course schedule arranged day-by-day. Each "Day N" corresponds to one dated section from your original list; dates have been removed as requested.

| Day | Topics |
|-----|--------|
| Day 1 | Keywords and identifiers; comments; indentation and statements; Variables and data types in Python; Standard Input and Output; Operators; Control flow: if else; Control flow: while loop |
| Day 2 | Module 1: Fundamentals of Programming; Python for DataScience; Control flow: for loop; Control flow: break and continue; Revision: Python for DataScience |
| Day 3 | Module 1: Fundamentals of Programming; Python for DataScience; Lists; Tuples part 1 & 2; Sets; Dictionary; Strings; Revision: Data Structures |
| Day 4 | Module 1: Fundamentals of Programming; Python for DataScience: Data Structures; Types of functions; Function arguments; Recursive functions; Lambda functions; Modules; Packages; File Handling |
| Day 5 | Module 1: Fundamentals of Programming; Python for DataScience: Functions; Exception Handling; Debugging Python; Assignment-1; Revision: Functions |
| Day 6 | Module 1: Fundamentals of Programming; Python for DataScience: Functions; Numpy Introduction; Numerical operations on Numpy; Revision: Numpy |
| Day 7 | Module 1: Fundamentals of Programming; Python for DataScience: Numpy; Getting started with Matplotlib; Revision: Matplotlib |
| Day 8 | Python for DataScience: Matplotlib; Getting started with pandas; Python for DataScience: Pandas; Data Frame Basics; Key Operations on Data Frames; Revision: Pandas |
| Day 9 | Module 1: Fundamentals of Programming; Python for DataScience: Computational Complexity; Space and Time Complexity examples (largest number in a list, Binary search); Find elements common in two lists (with and without hashtable/dict); Revision: Computational Complexity |
| Day 10 | Module 1: Fundamentals of Programming; Python for DataScience: Computational Complexity; Introduction to Databases; Why SQL?; Execution of an SQL statement; IMDB dataset; Installing MySQL; Load IMDB data; USE; DESCRIBE; SHOW TABLES; SELECT; LIMIT; OFFSET; ORDER BY; DISTINCT; WHERE; Comparison operators; NULL |
| Day 11 | Module 1: Fundamentals of Programming; SQL: Logical Operators; Aggregate Functions (COUNT, MIN, MAX, AVG, SUM); GROUP BY; HAVING; Order of keywords; Joins: Natural, Inner, Left, Right, Outer |
| Day 12 | Module 1: Fundamentals of Programming; SQL: Subqueries / Nested / Inner; DML: INSERT, UPDATE, DELETE; DDL: CREATE TABLE, ALTER (ADD/MODIFY/DROP), DROP TABLE, TRUNCATE; DCL: GRANT, REVOKE; Assignment-22: SQL on IMDB; Revision: SQL |
| Day 13 | Module 1: Fundamentals of Programming; SQL continuation; SQL revision exercises |
| Day 14 | Module 2: Exploratory Analysis & Data Visualization; Plotting for EDA; IRIS dataset: 2D/3D scatter plots, Pair plots; Histogram and PDF; Univariate analysis: PDF, CDF, Mean, Variance, Std Dev |
| Day 15 | Plotting for EDA continued; Median, Percentiles, Quantiles; IQR, MAD; Box-plot, Violin Plots; Univariate/Bivariate/Multivariate analysis; Multivariate PDF, Contour Plot; Exercise: EDA on Haberman |
| Day 16 | EDA plotting continued; Revision: EDA; Plotting for data analysis |
| Day 17 | Linear Algebra intro; Vectors (2D/3D/nD), Row/Column vectors; Dot product, Projection, Unit vector; Equations of lines/planes/hyperplanes; Distance to plane; Geometric shapes equations; Revision: Linear Algebra |
| Day 18 | Probability & Statistics intro; Population vs Sample; Gaussian/Normal distribution (PDF/CDF); Skewness, Kurtosis; Standardization; Kernel density estimation; Central Limit theorem |
| Day 19 | Q-Q plot for normality; Chebyshev’s inequality; Uniform distributions; Random sampling; Bernoulli and Binomial distributions |
| Day 20 | Log-normal & power-law distributions; Box-Cox transform; Applications of non-Gaussian distributions; Covariance; Pearson and Spearman correlations |
| Day 21 | Correlation vs Causation; Confidence Intervals; Bootstrapping for CI; Hypothesis testing, Null hypothesis, p-value |
| Day 22 | Resampling and permutation tests; K-S test; Code snippets and hypothesis testing examples |
| Day 23 | Proportional sampling; Revision questions |
| Day 24 | Dimensionality Reduction & Visualization; Feature Normalization; Column Standardization; Covariance matrix; MNIST dataset; Revision |
| Day 25 | PCA: Intuition, objective, eigenvalues/eigenvectors; PCA for visualization and reduction; Code examples |
| Day 26 | PCA continued; Revision: PCA |
| Day 27 | PCA continuation / short session |
| Day 28 | Module 3: Foundations of NLP & ML; Revision: Classification algorithms |
| Day 29 | Performance measurement: Accuracy, Confusion matrix, TPR/FPR/FNR/TNR; Precision, Recall, F1, ROC/AUC, Log-loss, R-Squared |
| Day 30 | MAD, Distribution of errors; Assignment-3: k-NN |
| Day 31 | Revision — Performance Measurement |
| Day 32 | Naive Bayes: Conditional probability, Bayes theorem, exercises |
| Day 33 | Naive Bayes: Train/test stages, text data, Laplace smoothing, log-probs, bias-variance, handling numeric features |
| Day 34 | Naive Bayes: Code example; Assignment-4 |
| Day 35 | Logistic Regression: intuition, sigmoid, objective |
| Day 36 | Logistic Regression: L2/L1 regularization, probabilistic interpretation |
| Day 37 | Hyperparameter search: Grid/Random Search; Standardization; Feature importance |
| Day 38 | Logistic Regression: code samples, GridSearchCV/RandomSearchCV; Assignment-5 |
| Day 39 | Logistic Regression — revision and extensions |
| Day 40 | Linear Regression: intuition, math, code samples |
| Day 41 | Solving optimization: differentiation, maxima/minima, gradient descent; Assignment-6: Implement SGD |
| Day 42 | Revision — Optimization Problems |
| Day 43 | SVM: geometric intuition, hinge loss, dual form |
| Day 44 | SVM: kernel trick, polynomial/RBF kernels, nu-SVM, regression |
| Day 45 | SVM — assignment & revision (Assignment-7) |
| Day 46 | Decision Trees: Entropy, Information Gain, splitting, categorical features |
| Day 47 | Decision Trees — revision and code samples (Assignment-8) |
| Day 48 | Ensemble Models: Bagging, Random Forests, Bias-Variance; Boosting: Gradient Boosting, XGBoost, AdaBoost, Stacking |
| Day 49 | Ensemble Models — Cascading classifiers, Kaggle vs real-world; Assignment-9 |
| Day 50 | Feature Engineering & Productionization: Featurization, Moving windows, Fourier features |
| Day 51 | Featurization: SIFT, CNN features, Relational/Graph data, Indicator variables |
| Day 52 | Featurization — Feature slicing, Kaggle winners' solutions |
| Day 53 | Calibration & Productionization: Platt scaling, Isotonic regression, RANSAC, Retraining strategies |
| Day 54 | Data Science lifecycle, VC dimension, Revision |
| Day 55 | Quora Question Pair Similarity — Problem definition, mapping to ML |
| Day 56 | Quora: Feature extraction (TF-IDF, Word2Vec), Models: Logistic, SVM, XGBoost |
| Day 57 | Personalized Cancer Diagnosis — Problem overview, EDA |
| Day 58 | Personalized Cancer Diagnosis — Modelling details, baseline models |
| Day 59 | Personalized Cancer Diagnosis — Random Forest variants, stacking, assignment |
| Day 60 | Facebook Friend Recommendation — Problem definition, graphs overview |
| Day 61 | Facebook Friend Recommendation — EDA and feature engineering on graphs |
| Day 62 | Facebook Friend Recommendation — Modeling, assignments, revision |
| Day 63 | Taxi Demand Prediction — Problem overview, data cleaning, feature engineering |
| Day 64 | Taxi Demand Prediction — Time-series preprocessing, smoothing, Fourier transforms; Regression models: Linear, RF, XGBoost |
| Day 65 | Taxi Demand Prediction — Revision and assignment |
| Day 66 | Stack Overflow Tag Predictor — Problem definition, multi-label classification |
| Day 67 | Stack Overflow Tag Predictor — Modeling and featurization, logistic one-vs-rest |
| Day 68 | Stack Overflow Tag Predictor — Revision and finalization |
| Day 69 | Microsoft Malware Detection — Problem definition, EDA, feature extraction from byte files |
| Day 70 | Microsoft Malware Detection — Models using byte files: K-NN, Logistic, RF, XGBoost |
| Day 71 | Microsoft Malware Detection — Revision |
| Day 72 | Clustering intro: K-Means intuition, centroids, objective function |
| Day 73 | Clustering — Failure cases, K-Medoids, choosing K, code samples |
| Day 74 | Hierarchical Clustering: Agglomerative & Divisive, Dendrograms |
| Day 75 | Hierarchical Clustering — Revision |
| Day 76 | DBSCAN: Density-based clustering, MinPts and Eps |
| Day 77 | Recommender Systems & Matrix Factorization — IMDB problem, content vs collaborative filtering |
| Day 78 | Recommender Systems — Cold-start, word vectors as MF, code examples; Assignment-11: Truncated SVD |
| Day 79 | Recommender Systems — Revision |
| Day 80 | Amazon Fashion Discovery Engine — Problem statement, text preprocessing, bag-of-words, TF-IDF, visual features |
| Day 81 | Amazon Fashion — IDF/Word2Vec/visual similarity, building solutions |
| Day 82 | Netflix Recommendation — Problem definition, temporal splits, sparse matrices |
| Day 83 | Netflix Recommendation — Similarity matrices, Surprise library, matrix factorization |
| Day 84 | Netflix Recommendation — Revision |
| Day 85 | Neural Networks intro: history, perceptrons, MLP |
| Day 86 | Neural Networks — notation, training single-neuron models, chain rule |
| Day 87 | Neural Networks — Backpropagation, activations, vanishing gradient |
| Day 88 | Neural Networks — Revision |
| Day 89 | Deep MLP — Dropout, ReLU, weight init, batch normalization |
| Day 90 | Deep MLP — Optimizers (SGD variants, Adam), gradient checking, softmax |
| Day 91 | Deep MLP — Training strategies, autoencoders, Word2Vec (CBOW/Skip-gram) |
| Day 92 | TensorFlow & Keras — Overview, GPU vs CPU, Colab, installing TensorFlow |
| Day 93 | TensorFlow & Keras — MLP architectures, batch norm, dropout, hyperparameter tuning |
| Day 94 | Convolutional Nets — Convolution, padding, strides |
| Day 95 | Convolutional Nets — Max-pooling, LeNet, ImageNet, data augmentation |
| Day 96 | Convolutional Nets — Inception, transfer learning, Cats vs Dogs example |
| Day 97 | Convolutional Nets — Revision |
| Day 98 | LSTMs — RNNs, training, why LSTM/GRU |
| Day 99 | LSTMs — Code example: IMDB sentiment classification |
| Day 100 | Human Activity Recognition — Problem definition, dataset, preprocessing, t-SNE visualization |
| Day 101 | Human Activity Recognition — Revision |
| Day 102 | Self Driving Car — Problem definition, datasets, dash-cam images, steering angles; Data splits; EDA; Baseline & deep models (CNN/RNN) |
| Day 103 | Self Driving Car — Testing, visualization, extensions, assignment |
| Day 104 | Music Generation — Char-RNN, data preparation, model architecture; MIDI music generation; assignments and revision |


